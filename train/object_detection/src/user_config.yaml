general:
  project_name: card_project
  model_type: st_ssd_mobilenet_v1
  model_path: 
  logs_dir: logs
  saved_models_dir: saved_models
  gpu_memory_limit: 4
  global_seed: 42
  display_figures: False

operation_mode: chain_tqe
#choices=['training' , 'evaluation', 'deployment', 'quantization', 'benchmarking',
#        'chain_tqeb','chain_tqe','chain_eqe','chain_qb','chain_eqeb','chain_qd '，'prediction']

dataset:
  name: card
  class_names: [ card ]
  training_path: ./dataset/train
  validation_path: ./dataset/valid
  test_path:
  quantization_path: 
  quantization_split: 0.2

prediction:
  test_files_path: ./dataset/test

preprocessing:
  rescaling: { scale: 1, offset: 0 } 
  # {scale: 1 / 127.5, offset -1} 这里为了部署方便不做处理
  resizing:
    aspect_ratio: fit
    interpolation: nearest
  color_mode: rgb

data_augmentation:
  rotation: 30
  shearing: 15
  translation: 0.1
  vertical_flip: 0.5
  horizontal_flip: 0.2
  gaussian_blur: 3.0
  linear_contrast: [ 0.75, 1.5 ]

training:
  model:
    alpha: 0.25
    input_shape: (192, 192, 3)
    pretrained_weights: imagenet
  dropout:
  batch_size: 64
  epochs: 500
  optimizer:
    Adam:
      learning_rate: 0.001
  callbacks:
    ReduceLROnPlateau:
      monitor: val_loss
      patience: 20
    EarlyStopping:
      monitor: val_loss
      patience: 40

postprocessing:
  confidence_thresh: 0.5
  NMS_thresh: 0.5
  IoU_eval_thresh: 0.3
  plot_metrics: True   # Plot precision versus recall curves. Default is False.
  max_detection_boxes: 10

quantization:
  quantizer: TFlite_converter
  quantization_type: PTQ
  quantization_input_type: uint8
  quantization_output_type: float
  # granularity: per_channel   #per_tensor
  # optimize: False   #can be True if per_tensor
  export_dir: quantized_models


mlflow:
  uri: ./experiments_outputs/mlruns

hydra:
  run:
    dir: ./experiments_outputs/${now:%Y_%m_%d_%H_%M_%S}_${operation_mode}